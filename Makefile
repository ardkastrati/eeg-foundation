
help:  ## Show help
	@grep -E '^[.a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-30s\033[0m %s\n", $$1, $$2}'

clean: ## Clean autogenerated files
	rm -rf dist
	find . -type f -name "*.DS_Store" -ls -delete
	find . | grep -E "(__pycache__|\.pyc|\.pyo)" | xargs rm -rf
	find . | grep -E ".pytest_cache" | xargs rm -rf
	find . | grep -E ".ipynb_checkpoints" | xargs rm -rf
	rm -f .coverage

clean-logs: ## Clean logs
	rm -rf logs/**

format: ## Run pre-commit hooks
	pre-commit run -a

sync: ## Merge changes from main branch to your current branch
	git pull
	git pull origin main

test: ## Run not slow tests
	pytest -k "not slow"

test-full: ## Run all tests
	pytest

train: ## Train the model
	python src/train.py experiment=maxim.yaml

trainexp:
	python src/train.py experiment=maxim.yaml

custom:
	srun --time 2:00:00 --gres=gpu:8 --nodelist=tikgpu02 --mem=300G --pty bash -i

cpu:
	srun --time 60 --gres=gpu:0 --mem=100G --pty bash -i

gpus: ## connect to GPU server cluster
	srun --time 1:00:00 --gres=gpu:3 --mem=300G --pty bash -i

gpuserver-60: ## connect to GPU server cluster
	srun --time 60 --gres=gpu:1 --pty bash -i

3gpu:
	srun --time 60 --gres=gpu:$(N) --mem=$(MEM) --pty bash -i

2node:
	srun --time 60 --gres=gpu:2 --nodes=2 --mem=40G --pty bash -i

serv:
	srun --time 60 --gres=gpu:1 --nodelist=$(N) --pty bash -i

10:
	srun --time 60 --gres=gpu:1 --nodelist=tikgpu10 --pty bash -i

logtb:
	tensorboard --logdir="/home/maxihuber/eeg-foundation/profiler_output/profiler0"

nb:
	jupyter lab --no-browser --port=8888

time:
	squeue -u maxihuber -o "%.18i %.9P %.8j %.8u %.2t %.10M %.10l %.6D %R"

free:
	alias smon_free="grep --color=always --extended-regexp 'free|$' /home/sladmitet/smon.txt"
	smon

duplicate:
	srun --jobid=$(ID) --overlap --pty bash -i

envinfo:
	python src/envinfo.py

compress:
	python src/utils/compresstraces.py

merge:
	python src/utils/mergetraces.py

symlinks:
	srun python src/utils/symlinks.py

mvtraces:
	python src/utils/movetraces.py

visualize:
	python src/utils/visualization_pipeline.py

tmp:
	sbatch /home/maxihuber/eeg-foundation/slurm/tmp.slurm

sbatch:
	sbatch /home/maxihuber/eeg-foundation/slurm/train.slurm

overnight:
	sbatch /home/maxihuber/eeg-foundation/slurm/overnight.slurm

scraper:
	sbatch /home/maxihuber/eeg-foundation/slurm/scraper.slurm

arraytrain:
	sbatch /home/maxihuber/eeg-foundation/slurm/arraytrain.slurm

output:
	tail -f /home/maxihuber/eeg-foundation/runs/sbatch/train_$(ID).out

errout:
	tail -f /home/maxihuber/eeg-foundation/runs/sbatch/train_$(ID).err

monitor:
	scontrol show job $(ID)

tboard:
	tensorboard --logdir=$(FOLDER) --bind_all --port=$(PORT)