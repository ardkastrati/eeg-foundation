{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9b1a80-cd86-4ed3-b427-f038f1e0601a",
   "metadata": {},
   "source": [
    "# Finetuning Notebook for NeuroBench"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f2d7d-b21d-4383-ac28-f6f3616c10aa",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ec7e8af-477d-4d7a-b00d-4c6a7da090ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import lightning as L\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import sys\n",
    "import random\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from mne.preprocessing import Xdawn\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, mean_squared_error\n",
    "\n",
    "mne.set_log_level('warning')\n",
    "sys.path.append(\"/home/maxihuber/eeg-foundation/\")\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea036b9-4979-4883-8acc-708017b99fb1",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3428f8de-eb21-492f-b8fd-a274c9a8d86a",
   "metadata": {},
   "source": [
    "### Load Train/Val/Test Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "140a137e-6e06-483e-8ff6-f9722725fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"/home/maxihuber/eeg-foundation/src/data/components/channels_to_id.json\", \"r\"\n",
    ") as f:\n",
    "    pkl_channels = set(json.load(f).keys())\n",
    "    cli_channels = set(\n",
    "        [\n",
    "            \"AF3\", \"AF4\", \"AF7\", \"AF8\", \"AFz\", \"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"C6\", \n",
    "            \"CP1\", \"CP2\", \"CP3\", \"CP4\", \"CP5\", \"CP6\", \"CPz\", \"Cz\", \"F1\", \"F2\", \"F3\", \n",
    "            \"F4\", \"F5\", \"F6\", \"F7\", \"F8\", \"FC1\", \"FC2\", \"FC3\", \"FC4\", \"FC5\", \"FC6\", \n",
    "            \"FCz\", \"FT7\", \"FT8\", \"Fp1\", \"Fp2\", \"Fz\", \"O1\", \"O2\", \"Oz\", \"P1\", \"P2\", \n",
    "            \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"PO3\", \"PO4\", \"PO7\", \"PO8\", \"POz\", \n",
    "            \"Pz\", \"T7\", \"T8\", \"TP7\", \"TP8\"\n",
    "        ]\n",
    "\n",
    "    )\n",
    "task_channels = pkl_channels | cli_channels\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "#Â TUAB and Epilepsy\n",
    "\n",
    "yc_class = {\n",
    "    \"class_name\": \"YC\",\n",
    "    \"time_col\": \"Time in Seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation/tueg/edf\",\n",
    "    \"load_mode\": 2,\n",
    "}\n",
    "\n",
    "tuab = {\n",
    "    \"task_name\": \"TUAB\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/cli/tuab.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "epilepsy = {\n",
    "    \"task_name\": \"Epilepsy\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/cli/epilepsy.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "########################################################################################################################\n",
    "# Clinical JSONs\n",
    "\n",
    "cli_class = {\n",
    "    \"class_name\": \"Clinical\",\n",
    "    \"time_col\": \"Time in Seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_clinical_prepared/\",\n",
    "    \"load_mode\": 0,\n",
    "}\n",
    "\n",
    "age = {\n",
    "    \"task_name\": \"Age\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_clinical_tasks/age.json\",\n",
    "    \"out_dim\": 1,\n",
    "}\n",
    "\n",
    "depression = {\n",
    "    \"task_name\": \"Depression\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_clinical_tasks/cli_depression.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "parkinsons = {\n",
    "    \"task_name\": \"Parkinsons\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_clinical_tasks/cli_parkinsons.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "schizophrenia = {\n",
    "    \"task_name\": \"Schizophrenia\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_clinical_tasks/cli_schizophrenia.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "sex = {\n",
    "    \"task_name\": \"Sex\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_clinical_tasks/sex.json\",\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "# Motor-Imagery JSONs\n",
    "\n",
    "mi_class = {\n",
    "    \"class_name\": \"Motor Imagery\",\n",
    "    \"time_col\": \"time in seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_prepared/\",\n",
    "    \"load_mode\": 0,\n",
    "}\n",
    "\n",
    "eye_open_closed = {\n",
    "    \"task_name\": \"EyeOpenClosed\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/mi/eye_open_closed.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"eye open\", \"eye closed\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "eye_vh = {\n",
    "    \"task_name\": \"EyeVH\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/mi/eye_vh.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"vertical\", \"horizontal\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "flexion_extension_imaginary = {\n",
    "    \"task_name\": \"FlexionExtensionImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/mi/flexion_extension_imaginary.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"hand movement imagined elbow flexion\",\n",
    "            \"hand movement imagined elbow extension\",\n",
    "        ]\n",
    "    ),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "flexion_extension_real = {\n",
    "    \"task_name\": \"FlexionExtensionReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/mi/flexion_extension_real.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"hand movement elbow extension\", \"hand movement elbow flexion\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "grasp_imaginary = {\n",
    "    \"task_name\": \"GraspImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/mi/grasp_imaginary.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"imagined palmar grasp\", \"imagined lateral grasp\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "grasp_real = {\n",
    "    \"task_name\": \"GraspReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/mi/grasp_real.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"movement palmar grasp\", \"movement lateral grasp\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "lr_imaginary = {\n",
    "    \"task_name\": \"LRImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/mi/lr_imaginary.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"left hand imagined movement\", \"right hand imagined movement\"]),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "lr_real = {\n",
    "    \"task_name\": \"LRReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/mi/lr_real.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"right hand movement\", \"left hand movement\"]),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "mi_task_body_parts_real = {\n",
    "    \"task_name\": \"BodyPartsReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/mi/mi_task_body_parts.json\",\n",
    "    \"out_dim\": 4,\n",
    "    \"outputs\": set(\n",
    "        [\"rest\", \"right hand movement\", \"foot movement\", \"left hand movement\"]\n",
    "    ),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "mi_task_body_parts_imagined = {\n",
    "    \"task_name\": \"BodyPartsImagined\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/mi/mi_task_body_parts.json\",\n",
    "    \"out_dim\": 4,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"rest\",\n",
    "            \"right hand imagined movement\",\n",
    "            \"foot imagined movement\",\n",
    "            \"left hand imagined movement\",\n",
    "            \"tongue imagined movement\",\n",
    "        ]\n",
    "    ),\n",
    "    \"short_mode\": True,\n",
    "}\n",
    "\n",
    "pronation_supination_real = {\n",
    "    \"task_name\": \"PronationSupinationReal\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/mi/pronation_supination_real.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"movement supination\", \"movement pronation\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "pronation_supination_imaginary = {\n",
    "    \"task_name\": \"PronationSupinationImaginary\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/mi/pronation_supination_imaginary.json\",\n",
    "    \"out_dim\": 2,\n",
    "    \"outputs\": set([\"imagined supination\", \"imagined pronation\"]),\n",
    "    \"short_mode\": False,\n",
    "}\n",
    "\n",
    "########################################################################################################################\n",
    "# ERP JSONs\n",
    "\n",
    "erp_class = {\n",
    "    \"class_name\": \"Error-Related Potential\",\n",
    "    \"time_col\": \"time in seconds\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_prepared/\",\n",
    "    \"load_mode\": 0,\n",
    "}\n",
    "\n",
    "erp = {\n",
    "    \"task_name\": \"ERP\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/erp/erp_all.json\",\n",
    "    \"out_dim\": 5,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"Participant is in resting state\",\n",
    "            \"with event-related potential\",\n",
    "            \"Participant is in interval between two flashes\",\n",
    "            \"without event-related potential\",\n",
    "            \"Participant keeps closing eyes\",\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "errp = {\n",
    "    \"task_name\": \"ERRP\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": \"/itet-stor/maxihuber/deepeye_storage/foundation_tasks/erp/errp_all.json\",\n",
    "    \"out_dim\": 7,\n",
    "    \"outputs\": set(\n",
    "        [\n",
    "            \"Target is located in the right\",\n",
    "            \"without error-related potential\",\n",
    "            \"The cursor moves to the left\",\n",
    "            \"The feedback consisted in the selected item is presented on the screen\",\n",
    "            \"The cursor moves to the right\",\n",
    "            \"with error-related potential\",\n",
    "            \"Target is located in the left\",\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "########################################################################################################################\n",
    "# EyeNet JSONs\n",
    "\n",
    "eye_class = {\n",
    "    \"class_name\": \"EyeNet\",\n",
    "    \"time_col\": \"time\",\n",
    "    \"prefix_filepath\": \"/itet-stor/maxihuber/deepeye_storage/foundation_prepared/\",\n",
    "    \"load_mode\": 1,\n",
    "}\n",
    "\n",
    "eye_dir_amp = {\n",
    "    \"task_name\": \"EyeNetDirectionAmp\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Amp_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Amp_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Amp_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 1,\n",
    "}\n",
    "\n",
    "eye_dir_ang = {\n",
    "    \"task_name\": \"EyeNetDirectionAng\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Ang_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Ang_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Direction_Ang_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 1,\n",
    "}\n",
    "\n",
    "eye_lr = {\n",
    "    \"task_name\": \"EyeNetLR\",\n",
    "    \"task_type\": \"Classification\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_LR_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_LR_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_LR_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 2,\n",
    "}\n",
    "\n",
    "eye_position = {\n",
    "    \"task_name\": \"EyeNetPosition\",\n",
    "    \"task_type\": \"Regression\",\n",
    "    \"json_path\": [\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Position_train.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Position_val.json\",\n",
    "        \"/itet-stor/maxihuber/deepeye_storage/eegeyenet_tasks/EEGEyeNet_Position_test.json\",\n",
    "    ],\n",
    "    \"out_dim\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b6468-0350-4044-99ba-3683577cd59b",
   "metadata": {},
   "source": [
    "### Load data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc2ba553-0c71-4133-9175-500d9b25fe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itet-stor/maxihuber/deepeye_storage/foundation_tasks/cli/epilepsy.json\n",
      "Full train size: 1838\n",
      "Full test size: 460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Load train data====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data:   1%|â                                                                                        | 13/1838 [00:11<27:51,  1.09it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Select the class and task\n",
    "\n",
    "used_class = yc_class\n",
    "# used_class = cli_class\n",
    "# used_class = mi_class\n",
    "# used_class = erp_class\n",
    "# used_class = eye_class\n",
    "#\n",
    "used_task = tuab\n",
    "# used_task = epilepsy\n",
    "# used_task = age\n",
    "# used_task = depression\n",
    "# used_task = parkinsons\n",
    "# used_task = schizophrenia\n",
    "# used_task = sex\n",
    "#\n",
    "# used_task = eye_open_closed\n",
    "# used_task = eye_vh\n",
    "# used_task = flexion_extension_imaginary\n",
    "# used_task = flexion_extension_real\n",
    "# used_task = grasp_real\n",
    "# used_task = lr_imaginary\n",
    "# used_task = lr_real\n",
    "# used_task = mi_task_body_parts_real\n",
    "# used_task = mi_task_body_parts_imagined\n",
    "# used_task = pronation_supination_real\n",
    "# used_task = pronation_supination_imaginary\n",
    "#\n",
    "# used_task = erp\n",
    "# used_task = errp\n",
    "#\n",
    "# used_task = eye_dir_amp\n",
    "# used_task = eye_dir_ang\n",
    "# used_task = eye_lr\n",
    "# used_task = eye_position\n",
    "\n",
    "class_name = used_class[\"class_name\"]\n",
    "time_col = used_class[\"time_col\"]\n",
    "prefix_filepath = used_class[\"prefix_filepath\"]\n",
    "load_mode = used_class[\"load_mode\"]\n",
    "task_name = used_task[\"task_name\"]\n",
    "task_type = used_task[\"task_type\"]\n",
    "json_path = used_task[\"json_path\"]\n",
    "out_dim = used_task[\"out_dim\"]\n",
    "short_mode = used_task[\"short_mode\"] if \"short_mode\" in used_task else False\n",
    "\n",
    "balance_datasets = True\n",
    "\n",
    "def load_index0(data_index_path):\n",
    "    with open(data_index_path, \"r\") as f:\n",
    "        train_test_dict = json.load(f)\n",
    "    train_samples = train_test_dict[\"train\"]\n",
    "    test_samples = train_test_dict[\"test\"]\n",
    "    return train_samples, test_samples\n",
    "\n",
    "\n",
    "def load_index1(data_index_paths):\n",
    "    all_samples = []\n",
    "    for data_index_path in data_index_paths:\n",
    "        with open(data_index_path, \"r\") as f:\n",
    "            subset_dict = json.load(f)\n",
    "        all_samples.append(list(subset_dict.values())[0])\n",
    "    return all_samples[0], all_samples[1], all_samples[2]\n",
    "\n",
    "\n",
    "dataset_dict = {\n",
    "    \"ERP_ERP_ANA\": 0,\n",
    "    \"RS_RS_ALPHA\": 1,\n",
    "    \"ERP_ERP_BISC\": 2,\n",
    "    \"ERP_ERP_BBI\": 3,\n",
    "    \"ERP_ERP_BICF\": 4,\n",
    "    \"ERP_ERP_BICD\": 5,\n",
    "    \"RS_RS_SPIS\": 6,\n",
    "    \"MI_MI_HGD\": 7,\n",
    "    \"MI_MI_SCP\": 8,\n",
    "    \"ErrP_ErrP_MERP\": 9,\n",
    "    \"MI_MI_ULM\": 10,\n",
    "    \"MI_MI_VEP\": 11,\n",
    "    \"MI_MI_LR\": 12,\n",
    "    \"MI_BBCI_IV_Graz_b\": 13,\n",
    "    \"MI_MI_EB\": 14,\n",
    "    \"MI_BBCI_IV_Graz_a\": 15,\n",
    "    \"MI_MI_GVH_V\": 16,\n",
    "    \"MI_MI_GAL\": 17,\n",
    "    \"MI_MI_Two\": 18,\n",
    "    \"MI_MI_GVH_H\": 19,\n",
    "    \"MI_MI_II\": 20,\n",
    "    \"ErrP_ErrP_BCI\": 21,\n",
    "    \"MI_MI_GVH_G\": 22,\n",
    "    \"MI_MI_Limb\": 23,\n",
    "    \"MI_MI_SCI\": 24,\n",
    "    \"MI_BBCI_IV_Berlin\": 25,\n",
    "    \"MI_eegmmidb\": 26,\n",
    "    \"ERP_ERP_FHD\": 27,\n",
    "    \"RS_RS_EID\": 28,\n",
    "}\n",
    "\n",
    "\n",
    "def extract_dataset_name(file_path, dataset_dict):\n",
    "    for name in dataset_dict.keys():\n",
    "        if name in file_path:\n",
    "            return name\n",
    "    return \"Unknown\"\n",
    "\n",
    "def get_generic_channel_name(channel_name):\n",
    "    channel_name = channel_name.lower()\n",
    "    # Remove \"eeg \" prefix if present\n",
    "    if channel_name.startswith(\"eeg \"):\n",
    "        channel_name = channel_name[4:]\n",
    "    # Simplify names with a dash and check if it ends with \"-\"\n",
    "    if \"-\" in channel_name:\n",
    "        if channel_name.endswith(\"-\"):\n",
    "            return \"None\"\n",
    "        return channel_name.split(\"-\")[0]\n",
    "    return channel_name\n",
    "\n",
    "def load_edf_to_dataframe(file_path):\n",
    "    eeg_data = mne.io.read_raw_edf(file_path, preload=True)\n",
    "    channel_data_dict = {}\n",
    "\n",
    "    for channel in eeg_data.ch_names:\n",
    "        idx = eeg_data.ch_names.index(channel)\n",
    "        channel = get_generic_channel_name(channel)\n",
    "        data, times = eeg_data[idx, :]\n",
    "        channel_data_dict[channel] = data.flatten()\n",
    "\n",
    "    df = pd.DataFrame(channel_data_dict)\n",
    "    df['Time in Seconds'] = times.flatten()\n",
    "    return df\n",
    "\n",
    "def load_file_data(data_index, task_channels):\n",
    "    num_samples = 0\n",
    "    data = {}\n",
    "    outputs = {}\n",
    "    srs = {}\n",
    "    durs = {}\n",
    "    channels = {}\n",
    "    datasets = {}\n",
    "    failed_samples = []\n",
    "\n",
    "    for sample in tqdm(data_index, desc=\"Loading data\", position=0, leave=True):\n",
    "        try:\n",
    "            # Load and concatenate dataframe\n",
    "            input_files = sample[\"input\"]\n",
    "\n",
    "            if load_mode == 2:\n",
    "                file = prefix_filepath + input_files[0] if \"/itet-stor\" not in input_files[0] else input_files[0]\n",
    "                df = load_edf_to_dataframe(file)\n",
    "            else:\n",
    "                df = pd.DataFrame()\n",
    "                for file in input_files:\n",
    "                    if load_mode != 1:\n",
    "                        file = prefix_filepath + file\n",
    "                    else:\n",
    "                        file = file.replace(\"/itet-stor/kard\", \"/itet-stor/maxihuber\")                       \n",
    "                    with open(file, \"rb\") as f:\n",
    "                        df_new = pd.read_pickle(f)\n",
    "                        df = pd.concat([df, df_new], axis=0)\n",
    "                    dataset_name = extract_dataset_name(file, dataset_dict)\n",
    "                    datasets[num_samples] = dataset_name\n",
    "\n",
    "            start = int(sample[\"start\"])\n",
    "            length = int(sample[\"length\"]) if \"length\" in sample else int(sample[\"end\"])\n",
    "            if load_mode != 1:\n",
    "                df = df.iloc[start:length, :]\n",
    "                if short_mode:\n",
    "                    df = df.iloc[: int(len(df) * 0.5), :]\n",
    "            else:\n",
    "                df = df.loc[start : start + length, :]\n",
    "\n",
    "            # Add metadata\n",
    "            if len(df) <= 1:\n",
    "                assert False\n",
    "            sr = int(\n",
    "                1 / float(float(df[time_col].iloc[1]) - float(df[time_col].iloc[0]))\n",
    "            )\n",
    "            if load_mode != 1:\n",
    "                outputs[num_samples] = (\n",
    "                    sample[\"output\"] if \"output\" in sample else sample[\"label\"]\n",
    "                )\n",
    "            else:\n",
    "                if task_name == \"EyeNetPosition\":\n",
    "                    outputs[num_samples] = list(sample[\"output\"].values())\n",
    "                else:\n",
    "                    outputs[num_samples] = list(sample[\"output\"].values())[0]\n",
    "            srs[num_samples] = sr\n",
    "            durs[num_samples] = len(df) / sr\n",
    "            channels[num_samples] = list(set(df.columns) & task_channels)\n",
    "            df = df[channels[num_samples]].astype(float)\n",
    "            signals = torch.tensor(df.to_numpy(), dtype=torch.float32).T\n",
    "            data[num_samples] = signals\n",
    "            num_samples += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process sample: {sample}. Error: {e}\", file=sys.stderr)\n",
    "            failed_samples.append(sample)\n",
    "\n",
    "    return data, outputs, srs, durs, channels, datasets\n",
    "\n",
    "\n",
    "if load_mode != 1:\n",
    "    print(json_path, file=sys.stderr)\n",
    "    train_index, test_index = load_index0(json_path)\n",
    "else:\n",
    "    train_index, val_index, test_index = load_index1(json_path)\n",
    "\n",
    "print(f\"Full train size: {len(train_index)}\", file=sys.stderr)\n",
    "print(f\"Full test size: {len(test_index)}\", file=sys.stderr)\n",
    "\n",
    "truncate = \"\"\"\n",
    "if load_mode == 0:\n",
    "    train_index = train_index\n",
    "    test_index = test_index\n",
    "elif load_mode == 1:\n",
    "    train_index = train_index\n",
    "    val_index = val_index\n",
    "    test_index = test_index\n",
    "else:\n",
    "    pass\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if load_mode == 0 or load_mode == 2:\n",
    "    print(\"=\" * 10 + \"Load train data\" + \"=\" * 100)\n",
    "    train_data, train_outputs, train_sr, train_dur, train_channels, train_datasets = (\n",
    "        load_file_data(train_index, task_channels)\n",
    "    )\n",
    "    print(\"=\" * 10 + \"Load test data\" + \"=\" * 100)\n",
    "    test_data, test_outputs, test_sr, test_dur, test_channels, test_datasets = (\n",
    "        load_file_data(test_index, task_channels)\n",
    "    )\n",
    "elif load_mode == 1:\n",
    "    train_data, train_outputs, train_sr, train_dur, train_channels, train_datasets = (\n",
    "        load_file_data(train_index, task_channels)\n",
    "    )\n",
    "    val_data, val_outputs, val_sr, val_dur, val_channels, val_datasets = load_file_data(\n",
    "        val_index, task_channels\n",
    "    )\n",
    "    test_data, test_outputs, test_sr, test_dur, test_channels, test_datasets = (\n",
    "        load_file_data(test_index, task_channels)\n",
    "    )\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Label Encoder & Class Weights\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "if isinstance(list(train_outputs.values())[0], str):\n",
    "    all_outputs = list(set(list(train_outputs.values()) + list(test_outputs.values())))\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(all_outputs)\n",
    "\n",
    "    print(f\"Train classes: {set(train_outputs.values())}\", file=sys.stderr)\n",
    "    print(f\"Test classes: {set(test_outputs.values())}\", file=sys.stderr)\n",
    "\n",
    "    # Encode the train and test outputs\n",
    "    encoded_train_outputs = {\n",
    "        k: label_encoder.transform([v])[0] for k, v in train_outputs.items()\n",
    "    }\n",
    "    encoded_test_outputs = {\n",
    "        k: label_encoder.transform([v])[0] for k, v in test_outputs.items()\n",
    "    }\n",
    "\n",
    "    # Create the output counts map\n",
    "    train_output_counts = defaultdict(int)\n",
    "    for output in encoded_train_outputs.values():\n",
    "        train_output_counts[output] += 1\n",
    "\n",
    "    test_output_counts = defaultdict(int)\n",
    "    for output in encoded_test_outputs.values():\n",
    "        test_output_counts[output] += 1\n",
    "\n",
    "    full_output_counts = train_output_counts.copy()\n",
    "    for output, count in test_output_counts.items():\n",
    "        full_output_counts[output] += count\n",
    "\n",
    "    print(\"Full Output Counts:\", full_output_counts, file=sys.stderr)\n",
    "\n",
    "    # Calculate class weights\n",
    "    total_count = sum(full_output_counts.values())\n",
    "    class_weights = {\n",
    "        output: total_count / count for output, count in full_output_counts.items()\n",
    "    }\n",
    "\n",
    "    # Convert class weights to a tensor\n",
    "    weight_tensor = torch.tensor(\n",
    "        [class_weights[i] for i in range(len(class_weights))], dtype=torch.float\n",
    "    )\n",
    "else:\n",
    "    label_encoder = None\n",
    "    weight_tensor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db9d9b-e3e5-408a-a3f1-c0815e6120c6",
   "metadata": {},
   "source": [
    "# Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209adf01-7017-441f-89ca-26f3ed83bcec",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "70195951-8bb9-4c86-b150-093cee423457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n",
      "/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.9 /itet-stor/maxihuber/net_scratch/conda_envs/faste ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory /srv/beegfs01/projects/deepeye_storage/data/finetune_ckpts/EyeOpenClosed exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                         | Type                                 | Params | Mode \n",
      "----------------------------------------------------------------------------------------------\n",
      "0 | encoder                      | EncoderViTRoPE                       | 23.1 M | train\n",
      "1 | finetune_time_transformer    | Flexible_RoPE_Layer_scale_init_Block | 1.8 M  | train\n",
      "2 | finetune_channel_transformer | SimpleTransformer                    | 1.8 M  | train\n",
      "3 | head                         | Linear                               | 770    | train\n",
      "4 | criterion                    | CrossEntropyLoss                     | 0      | train\n",
      "----------------------------------------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "23.1 M    Non-trainable params\n",
      "26.7 M    Total params\n",
      "106.694   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Motor Imagery\n",
      "Task: EyeOpenClosed (Classification)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fc0a109a1249d8a40f5f1e0c7aa6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2446: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfroze encoder at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.9 /itet-stor/maxihuber/net_scratch/conda_envs/faste ...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fae00787b704d6cbc9da79140a5d64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                                    â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ââââââââââââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââââââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\">               Test metric                </span>â<span style=\"font-weight: bold\">               DataLoader 0               </span>â\n",
       "â¡ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â<span style=\"color: #008080; text-decoration-color: #008080\">          test_balanced_accuracy          </span>â<span style=\"color: #800080; text-decoration-color: #800080\">            0.6944444179534912            </span>â\n",
       "â<span style=\"color: #008080; text-decoration-color: #008080\"> test_balanced_accuracy_MI_BBCI_IV_Graz_a </span>â<span style=\"color: #800080; text-decoration-color: #800080\">                   1.0                    </span>â\n",
       "â<span style=\"color: #008080; text-decoration-color: #008080\"> test_balanced_accuracy_MI_BBCI_IV_Graz_b </span>â<span style=\"color: #800080; text-decoration-color: #800080\">                   0.5                    </span>â\n",
       "â<span style=\"color: #008080; text-decoration-color: #008080\">    test_balanced_accuracy_RS_RS_ALPHA    </span>â<span style=\"color: #800080; text-decoration-color: #800080\">            0.6666666865348816            </span>â\n",
       "â<span style=\"color: #008080; text-decoration-color: #008080\">    test_balanced_accuracy_RS_RS_SPIS     </span>â<span style=\"color: #800080; text-decoration-color: #800080\">                   0.5                    </span>â\n",
       "â<span style=\"color: #008080; text-decoration-color: #008080\">                test_loss                 </span>â<span style=\"color: #800080; text-decoration-color: #800080\">            1.2859755754470825            </span>â\n",
       "ââââââââââââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââââââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ââââââââââââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââââââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1m              Test metric               \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m              DataLoader 0              \u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â\u001b[36m \u001b[0m\u001b[36m         test_balanced_accuracy         \u001b[0m\u001b[36m \u001b[0mâ\u001b[35m \u001b[0m\u001b[35m           0.6944444179534912           \u001b[0m\u001b[35m \u001b[0mâ\n",
       "â\u001b[36m \u001b[0m\u001b[36mtest_balanced_accuracy_MI_BBCI_IV_Graz_a\u001b[0m\u001b[36m \u001b[0mâ\u001b[35m \u001b[0m\u001b[35m                  1.0                   \u001b[0m\u001b[35m \u001b[0mâ\n",
       "â\u001b[36m \u001b[0m\u001b[36mtest_balanced_accuracy_MI_BBCI_IV_Graz_b\u001b[0m\u001b[36m \u001b[0mâ\u001b[35m \u001b[0m\u001b[35m                  0.5                   \u001b[0m\u001b[35m \u001b[0mâ\n",
       "â\u001b[36m \u001b[0m\u001b[36m   test_balanced_accuracy_RS_RS_ALPHA   \u001b[0m\u001b[36m \u001b[0mâ\u001b[35m \u001b[0m\u001b[35m           0.6666666865348816           \u001b[0m\u001b[35m \u001b[0mâ\n",
       "â\u001b[36m \u001b[0m\u001b[36m   test_balanced_accuracy_RS_RS_SPIS    \u001b[0m\u001b[36m \u001b[0mâ\u001b[35m \u001b[0m\u001b[35m                  0.5                   \u001b[0m\u001b[35m \u001b[0mâ\n",
       "â\u001b[36m \u001b[0m\u001b[36m               test_loss                \u001b[0m\u001b[36m \u001b[0mâ\u001b[35m \u001b[0m\u001b[35m           1.2859755754470825           \u001b[0m\u001b[35m \u001b[0mâ\n",
       "ââââââââââââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââââââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.2859755754470825,\n",
       "  'test_balanced_accuracy_MI_BBCI_IV_Graz_a': 1.0,\n",
       "  'test_balanced_accuracy_MI_BBCI_IV_Graz_b': 0.5,\n",
       "  'test_balanced_accuracy_RS_RS_ALPHA': 0.6666666865348816,\n",
       "  'test_balanced_accuracy_RS_RS_SPIS': 0.5,\n",
       "  'test_balanced_accuracy': 0.6944444179534912}]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(42)\n",
    "\n",
    "ckpt_path = '/itet-stor/maxihuber/net_scratch/checkpoints/980473/epoch=7-step=239317-val_loss=130.45-lr.ckpt'\n",
    "ckpt_path = '/itet-stor/maxihuber/net_scratch/checkpoints/977598/epoch=0-step=32807-val_loss=133.55.ckpt'\n",
    "\n",
    "#########################################################################################################\n",
    "class FinetuneDataset(Dataset):\n",
    "    def __init__(self, data, outputs, srs, durs, channels, datasets, task_type, label_encoder=None):\n",
    "        self.data = data\n",
    "        self.outputs = outputs\n",
    "        self.srs = srs\n",
    "        self.durs = durs\n",
    "        self.channels = channels\n",
    "        self.datasets = datasets\n",
    "        self.task_type = task_type\n",
    "        self.label_encoder = label_encoder\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        signals = self.data[idx]\n",
    "        output = self.outputs[idx]\n",
    "        sr = self.srs[idx]\n",
    "        dur = self.durs[idx]\n",
    "        channels = self.channels[idx]\n",
    "        dataset = self.datasets[idx]\n",
    "\n",
    "        if self.task_type == \"Classification\" and self.label_encoder is not None:\n",
    "            output = self.label_encoder.transform([output])[0]  # Encode the output label\n",
    "            output_tensor = torch.tensor(output, dtype=torch.long)\n",
    "        else:\n",
    "            if task_name == \"EyeNetPosition\":\n",
    "                output_tensor = torch.tensor(output, dtype=torch.float32)\n",
    "            else:\n",
    "                output_tensor = torch.tensor([output], dtype=torch.float32)\n",
    "        \n",
    "        return {\n",
    "            \"signals\": signals,\n",
    "            \"output\": output_tensor,\n",
    "            \"sr\": sr,\n",
    "            \"dur\": dur,\n",
    "            \"channels\": channels,\n",
    "            \"dataset\": dataset\n",
    "        }\n",
    "\n",
    "if load_mode == 0:\n",
    "    full_train_dataset = FinetuneDataset(train_data, train_outputs, train_sr, train_dur, train_channels, train_datasets, task_type=task_type, label_encoder=label_encoder)\n",
    "    test_dataset = FinetuneDataset(test_data, test_outputs, test_sr, test_dur, test_channels, test_datasets, task_type=task_type, label_encoder=label_encoder)\n",
    "    # Define the split ratio\n",
    "    train_ratio = 0.85\n",
    "    val_ratio = 0.15\n",
    "    # Calculate lengths for train and validation sets\n",
    "    total_size = len(full_train_dataset)\n",
    "    train_size = int(train_ratio * total_size)\n",
    "    val_size = total_size - train_size\n",
    "    # Split the dataset\n",
    "    train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "elif load_mode == 1:\n",
    "    train_dataset = FinetuneDataset(train_data, train_outputs, train_sr, train_dur, train_channels, train_datasets, task_type=task_type, label_encoder=label_encoder)\n",
    "    val_dataset = FinetuneDataset(val_data, val_outputs, val_sr, val_dur, val_channels, val_datasets, task_type=task_type, label_encoder=label_encoder)\n",
    "    test_dataset = FinetuneDataset(test_data, test_outputs, test_sr, test_dur, test_channels, test_datasets, task_type=task_type, label_encoder=label_encoder)\n",
    "else:\n",
    "    pass\n",
    "    \n",
    "#########################################################################################################\n",
    "# DataLoaders\n",
    "import torchaudio\n",
    "from src.data.transforms import (\n",
    "    crop_spg,\n",
    "    custom_fft,\n",
    "    normalize_spg,\n",
    ")\n",
    "\n",
    "self_win_shifts = [.25, .5, 1, 2, 4, 8]\n",
    "self_patch_size = 16\n",
    "self_win_shift_factor = .25\n",
    "self_max_win_shift = self_win_shifts[-1]\n",
    "self_max_y_datapoints = 4_000\n",
    "\n",
    "def get_nr_y_patches(win_size, sr):\n",
    "    return int((sr / 2 * win_size + 1) / self_patch_size)\n",
    "\n",
    "def get_nr_x_patches(win_size, dur):\n",
    "    win_shift = win_size * self_win_shift_factor\n",
    "    x_datapoints_per_second = 1 / win_shift\n",
    "    x_datapoints = dur * x_datapoints_per_second + 1\n",
    "    return int(x_datapoints // self_patch_size)\n",
    "\n",
    "channel_name_map_path = '/home/maxihuber/eeg-foundation/src/data/components/channels_to_id.json'\n",
    "with open(channel_name_map_path, \"r\") as file:\n",
    "    self_channel_name_map = json.load(file)\n",
    "\n",
    "def self_get_generic_channel_name(channel_name):\n",
    "    channel_name = channel_name.lower()\n",
    "    # Remove \"eeg \" prefix if present\n",
    "    if channel_name.startswith(\"eeg \"):\n",
    "        channel_name = channel_name[4:]\n",
    "    # Simplify names with a dash and check if it ends with \"-\"\n",
    "    if \"-\" in channel_name:\n",
    "        if channel_name.endswith(\"-\"):\n",
    "            return \"None\"\n",
    "        return channel_name.split(\"-\")[0]\n",
    "    return channel_name\n",
    "\n",
    "def self_encode_mean(mean, win_size):\n",
    "    y_datapoints = mean.shape[0]\n",
    "    encoded_mean = torch.zeros(self_max_y_datapoints)\n",
    "    step_size = int(self_max_win_shift // win_size)\n",
    "    end_idx = step_size * y_datapoints\n",
    "    indices = torch.arange(0, end_idx, step_size)\n",
    "    encoded_mean[indices] = mean.squeeze_().float()\n",
    "    encoded_mean.unsqueeze_(1)\n",
    "    return encoded_mean\n",
    "\n",
    "#########################################################################################################\n",
    "# collate_fn\n",
    "#Â make batches as the pre-trained network expects (channel tokens, means, standard deviation etc.)\n",
    "def sample_collate_fn(batch):\n",
    "\n",
    "    signals, output, sr, dur, channels, dataset = batch[0][\"signals\"], batch[0][\"output\"], batch[0][\"sr\"], batch[0][\"dur\"], batch[0][\"channels\"], batch[0][\"dataset\"]\n",
    "\n",
    "    if dur > 3_600:\n",
    "        dur = 3_600\n",
    "        signals = signals[:, :3_600*sr]\n",
    "        \n",
    "    # TODO: compute spectrograms for each win_size\n",
    "    # gives a new dimension (S) in batch\n",
    "    #Â need another extra transformer after the encoder\n",
    "    # (B, 1, H, W) -> (S*B, 1, H, W)\n",
    "    valid_win_shifts = [\n",
    "        win_shift\n",
    "        for win_shift in self_win_shifts\n",
    "        if get_nr_y_patches(win_shift, sr) >= 1\n",
    "        and get_nr_x_patches(win_shift, dur) >= 1\n",
    "    ]\n",
    "\n",
    "    # list holding assembled tensors for varying window shifts\n",
    "    full_batch = {}   \n",
    "\n",
    "    for win_size in valid_win_shifts:\n",
    "        \n",
    "        fft = torchaudio.transforms.Spectrogram(\n",
    "            n_fft=int(sr * win_size),\n",
    "            win_length=int(sr * win_size),\n",
    "            hop_length=int(sr * win_size * self_win_shift_factor),\n",
    "            normalized=True,\n",
    "        )\n",
    "    \n",
    "        spg_list = []\n",
    "        chn_list = []\n",
    "        mean_list = []\n",
    "        std_list = []\n",
    "    \n",
    "        for signal, channel in zip(signals, channels):\n",
    "            \n",
    "            #Â Channel information\n",
    "            channel_name = self_get_generic_channel_name(channel)\n",
    "            channel = self_channel_name_map[channel_name] if channel_name in self_channel_name_map else self_channel_name_map[\"None\"]\n",
    "    \n",
    "            # Spectrogram Computation & Cropping\n",
    "            spg = fft(signal)\n",
    "            spg = spg**2\n",
    "            spg = crop_spg(spg, self_patch_size)\n",
    "            \n",
    "            H_new, W_new = spg.shape[0], spg.shape[1]\n",
    "            h_new, w_new = H_new // self_patch_size, W_new // self_patch_size\n",
    "    \n",
    "            # Prepare channel information (per-patch)\n",
    "            channel = torch.full((h_new, w_new), channel, dtype=torch.float16)\n",
    "            \n",
    "            spg, mean, std = normalize_spg(spg)\n",
    "            mean = self_encode_mean(mean, win_size)\n",
    "            std = self_encode_mean(std, win_size)\n",
    "            \n",
    "            spg_list.append(spg)\n",
    "            chn_list.append(channel)\n",
    "            mean_list.append(mean)\n",
    "            std_list.append(std)\n",
    "        \n",
    "        win_batch = torch.stack(spg_list)\n",
    "        win_channels = torch.stack(chn_list)\n",
    "        win_means = torch.stack(mean_list)\n",
    "        win_stds = torch.stack(std_list)\n",
    "        \n",
    "        win_batch.unsqueeze_(1)\n",
    "        win_channels = win_channels.flatten(1)\n",
    "        win_means = win_means.transpose(1, 2)\n",
    "        win_stds = win_stds.transpose(1, 2)\n",
    "        \n",
    "        full_batch[win_size] = {\n",
    "            \"batch\": win_batch,\n",
    "            \"channels\": win_channels,\n",
    "            \"means\": win_means,\n",
    "            \"stds\": win_stds\n",
    "        }\n",
    "        #print(f\"[collate_fn] win_size={win_size}: {win_batch.shape}\")\n",
    "        \n",
    "    # == Finished iterating over all possible window shifts\n",
    "   \n",
    "    return full_batch, output, dataset\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, collate_fn=sample_collate_fn, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, collate_fn=sample_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=sample_collate_fn)\n",
    "\n",
    "#########################################################################################################\n",
    "# Model\n",
    "# == Metrics ==\n",
    "def rmse(y_true, y_pred):\n",
    "    return torch.sqrt(torch.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    return balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from src.models.mae_rope_encoder import EncoderViTRoPE\n",
    "from src.models.components.vit_rope import (\n",
    "    Flexible_RoPE_Layer_scale_init_Block,\n",
    "    FlexibleRoPEAttention,\n",
    "    compute_axial_cis,\n",
    "    select_freqs_cis,\n",
    ")\n",
    "from timm.models.vision_transformer import Mlp as Mlp\n",
    "\n",
    "from torch.nn import TransformerEncoderLayer\n",
    "class SingleTransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead):\n",
    "        super(SingleTransformerEncoderLayer, self).__init__()\n",
    "        self.encoder_layer = TransformerEncoderLayer(d_model, nhead)\n",
    "\n",
    "    def forward(self, src):\n",
    "        return self.encoder_layer(src)\n",
    "\n",
    "from src.models.components.SimpleTransformer import SimpleTransformer\n",
    "\n",
    "def mean_aggregation(tokens):\n",
    "    return torch.mean(torch.stack(tokens), dim=0)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchmetrics\n",
    "\n",
    "class FineTuningModel(L.LightningModule):\n",
    "    def __init__(self, encoder, frozen_encoder, out_dim, task_name, task_type, learning_rate, mask_ratio):\n",
    "        super(FineTuningModel, self).__init__()\n",
    "\n",
    "        self.task_name = task_name\n",
    "        self.task_type = task_type\n",
    "        self.learning_rate = learning_rate\n",
    "        self.mask_ratio = mask_ratio\n",
    "\n",
    "        # Pretrained network\n",
    "        self.encoder = encoder       \n",
    "        if frozen_encoder:\n",
    "            self.freeze_encoder()\n",
    "\n",
    "        # Finetuning network\n",
    "        self.finetune_time_transformer = Flexible_RoPE_Layer_scale_init_Block(\n",
    "            dim=384,\n",
    "            num_heads=6,\n",
    "            mlp_ratio=4,\n",
    "            qkv_bias=True,\n",
    "            drop=0.0,\n",
    "            attn_drop=0.0,\n",
    "            drop_path=0.0,\n",
    "            norm_layer=partial(nn.LayerNorm, eps=1e-6),\n",
    "            act_layer=nn.GELU,\n",
    "            Attention_block=FlexibleRoPEAttention,\n",
    "            Mlp_block=Mlp,\n",
    "            init_values=1e-4,\n",
    "        )\n",
    "        \n",
    "        # Single 1D transformer encoder layer\n",
    "        #self.finetune_channel_transformer = SingleTransformerEncoderLayer(\n",
    "        #    d_model=384,  # Match the dimension used in finetune_time_transformer\n",
    "        #    nhead=1       # Number of heads in the multiheadattention models\n",
    "        #)\n",
    "        self.finetune_channel_transformer = SimpleTransformer(\n",
    "            embed_size=384,\n",
    "            max_len=8_500,\n",
    "        )\n",
    "        \n",
    "        # Modular aggregation method on channel tokens\n",
    "        self.win_shift_aggregation = mean_aggregation\n",
    "        \n",
    "        if task_type == \"Regression\":\n",
    "            self.head = nn.Linear(encoder.encoder_embed_dim, out_dim)\n",
    "            self.criterion = nn.MSELoss()\n",
    "        else:\n",
    "            self.head = nn.Linear(encoder.encoder_embed_dim, out_dim)\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.train_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "    def forward(self, full_x):\n",
    "        \n",
    "        x_embeds = {}\n",
    "        H_W = {}\n",
    "        \n",
    "        for win_size, x_win in full_x.items():\n",
    "            spgs = x_win[\"batch\"]\n",
    "            channels = x_win[\"channels\"]\n",
    "            means = x_win[\"means\"]\n",
    "            stds = x_win[\"stds\"]\n",
    "            B, C, H, W = spgs.shape\n",
    "            # TODO: split into less rows if necessary because of CUDA error\n",
    "            #nr_tokens = B * C * H * W\n",
    "            #if nr_tokens > max_nr_tokens:\n",
    "            #    pass\n",
    "            x_emb, _, _, nr_meta_patches = self.encoder(\n",
    "                x=spgs,\n",
    "                means=means,\n",
    "                stds=stds,\n",
    "                channels=channels,\n",
    "                win_size=win_size,\n",
    "                mask_ratio=self.mask_ratio,\n",
    "            )\n",
    "            #Â TODO: \n",
    "            x_embeds[win_size] = x_emb\n",
    "            H_W[win_size] = (H, W)\n",
    "            #print(f\"[FT.forward, after self.encoder] x_emb.shape: {x_emb.shape}\")\n",
    "\n",
    "        # Pass through time-transformer\n",
    "        for win_size, x_emb in x_embeds.items():\n",
    "            freqs_cis = select_freqs_cis(\n",
    "                self.encoder, self.encoder.encoder_freqs_cis, H_W[win_size][0], H_W[win_size][1], win_size, x_emb.device\n",
    "            )\n",
    "            x_emb = self.finetune_time_transformer(x_emb, freqs_cis=freqs_cis, nr_meta_tokens=nr_meta_patches)\n",
    "            #print(f\"[FT.forward, after self.time_transformer] x_emb.shape: {x_emb.shape}\")\n",
    "            x_emb = x_emb[:, 0]\n",
    "            #print(f\"[FT.forward, after time-token] x_emb.shape: {x_emb.shape}\")\n",
    "            x_embeds[win_size] = x_emb\n",
    "\n",
    "        # Pass through channel-transformer\n",
    "        tokens = []\n",
    "        for win_size, x_emb in x_embeds.items():\n",
    "            x_emb = x_emb.unsqueeze(0)\n",
    "            #print(f\"[FT.forward, before channel-token] x_emb.shape: {x_emb.shape}\")\n",
    "            x_emb = self.finetune_channel_transformer(x_emb)\n",
    "            x_emb = x_emb[0, 0]\n",
    "            #print(f\"[FT.forward, after channel-token] x_emb.shape: {x_emb.shape}\")\n",
    "            tokens.append(x_emb)\n",
    "\n",
    "        #print(f\"[FT.forward] len(tokens): {len(tokens)}\")\n",
    "        # Average over all window shifts\n",
    "        smart_token = self.win_shift_aggregation(tokens)\n",
    "        #print(f\"[FT.forward] smart_token.shape: {smart_token.shape}\")\n",
    "\n",
    "        # Pass through head\n",
    "        y_hat = self.head(smart_token)\n",
    "        \n",
    "        return y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, dataset = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(input=y_hat, target=y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "\n",
    "        if self.task_type == \"Classification\":\n",
    "            y_pred = torch.argmax(y_hat, dim=0)\n",
    "            #print(f\"[training_step] y_hat={y_hat}, y_pred={y_pred}, y={y}, loss={loss}\")\n",
    "            self.train_step_outputs.append((y.cpu(), y_pred.cpu(), dataset))\n",
    "        elif self.task_type == \"Regression\":\n",
    "            self.train_step_outputs.append((y.cpu(), y_hat.cpu(), dataset))\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.compute_metrics(self.train_step_outputs, 'train')\n",
    "        self.train_step_outputs.clear()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, dataset = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(input=y_hat, target=y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "        if self.task_type == \"Classification\":\n",
    "            y_pred = torch.argmax(y_hat, dim=0)\n",
    "            #print(f\"[validation_step] y_pred={y_pred}, y={y}, loss={loss}\")\n",
    "            self.validation_step_outputs.append((y.cpu(), y_pred.cpu(), dataset))\n",
    "        elif self.task_type == \"Regression\":\n",
    "            self.validation_step_outputs.append((y.cpu(), y_hat.cpu(), dataset))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.compute_metrics(self.validation_step_outputs, 'val')\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, dataset = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(input=y_hat, target=y)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "\n",
    "        if self.task_type == \"Classification\":\n",
    "            y_pred = torch.argmax(y_hat, dim=0)\n",
    "            #print(f\"[test_step] y_pred={y_pred}, y={y}, loss={loss}\")\n",
    "            self.test_step_outputs.append((y.cpu(), y_pred.cpu(), dataset))\n",
    "        elif self.task_type == \"Regression\":\n",
    "            self.test_step_outputs.append((y.cpu(), y_hat.cpu(), dataset))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.compute_metrics(self.test_step_outputs, 'test')\n",
    "        self.test_step_outputs.clear()\n",
    "\n",
    "    def compute_metrics(self, outputs, stage):\n",
    "        y_true_all = defaultdict(list)\n",
    "        y_pred_all = defaultdict(list)\n",
    "        \n",
    "        for y_true, y_pred, dataset in outputs:\n",
    "            y_true_all[dataset].append(y_true)\n",
    "            y_pred_all[dataset].append(y_pred)\n",
    "\n",
    "        overall_y_true = []\n",
    "        overall_y_pred = []\n",
    "\n",
    "        for dataset in y_true_all.keys():\n",
    "            y_true_cat = torch.stack(y_true_all[dataset])\n",
    "            y_pred_cat = torch.stack(y_pred_all[dataset])\n",
    "\n",
    "            overall_y_true.append(y_true_cat)\n",
    "            overall_y_pred.append(y_pred_cat)\n",
    "\n",
    "            if self.task_type == \"Classification\":\n",
    "                balanced_acc = balanced_accuracy_score(y_true_cat, y_pred_cat)\n",
    "                self.log(f'{stage}_balanced_accuracy_{dataset}', balanced_acc, prog_bar=True)\n",
    "            elif self.task_type == \"Regression\":\n",
    "                rmse_value = rmse(y_true_cat, y_pred_cat)\n",
    "                self.log(f'{stage}_rmse_{dataset}', rmse_value, prog_bar=True)\n",
    "\n",
    "        # Compute overall metrics\n",
    "        overall_y_true = torch.cat(overall_y_true, dim=0)\n",
    "        overall_y_pred = torch.cat(overall_y_pred, dim=0)\n",
    "\n",
    "        if self.task_type == \"Classification\":\n",
    "            balanced_acc = balanced_accuracy_score(overall_y_true, overall_y_pred)\n",
    "            self.log(f'{stage}_balanced_accuracy', balanced_acc, prog_bar=True)\n",
    "        elif self.task_type == \"Regression\":\n",
    "            rmse_value = rmse(overall_y_true, overall_y_pred)\n",
    "            self.log(f'{stage}_rmse', rmse_value, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.head.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        if trainer.current_epoch == 1:\n",
    "            self.unfreeze_encoder()\n",
    "            print(f\"Unfroze encoder at epoch {self.trainer.current_epoch}\")\n",
    "        \n",
    "    def freeze_encoder(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_encoder(self):\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "#########################################################################################################\n",
    "# Load the checkpoint\n",
    "chkpt_path = ckpt_path\n",
    "checkpoint = torch.load(chkpt_path, map_location=torch.device('cpu'))\n",
    "state_dict = checkpoint['state_dict']\n",
    "state_dict = {k.replace(\"net.encoder.\", \"\"): v for k, v in state_dict.items() if \"net.encoder.\" in k}\n",
    "\n",
    "# Initialize the encoder and load the state dict\n",
    "encoder = EncoderViTRoPE(channel_name_map_path)\n",
    "encoder.load_state_dict(state_dict)\n",
    "\n",
    "# Instantiate the fine-tuning model\n",
    "fine_tuning_model = FineTuningModel(encoder=encoder,\n",
    "                                    frozen_encoder=True,\n",
    "                                    out_dim=out_dim,\n",
    "                                    task_name=task_name,\n",
    "                                    task_type=task_type,\n",
    "                                    learning_rate=0.01,\n",
    "                                    mask_ratio=0)\n",
    "\n",
    "#########################################################################################################\n",
    "# Define the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"/itet-stor/maxihuber/deepeye_storage/finetune_ckpts/{task_name}\",\n",
    "    filename=\"{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_top_k=3,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=5,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    log_every_n_steps=1,\n",
    "    num_sanity_val_steps=0,\n",
    ")\n",
    "\n",
    "print(f\"Class: {class_name}\")\n",
    "print(f\"Task: {task_name} ({task_type})\")\n",
    "trainer.fit(fine_tuning_model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "trainer.test(model=fine_tuning_model, dataloaders=test_loader)\n",
    "final_checkpoint_path = f\"/itet-stor/maxihuber/net_scratch/finetune_ckpts/{task_name}/final_model.ckpt\"\n",
    "trainer.save_checkpoint(final_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b791b7-42dc-4dbc-9ac9-9f4bd15bfe98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b94ab25-0207-4ad1-9f84-cd20a5a7b9f7",
   "metadata": {},
   "source": [
    "## Data Preparation & Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c10a439-4077-46d6-97fb-0f8100db896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "L.seed_everything(42)\n",
    "\n",
    "sys.path.append(\"/home/maxihuber/eeg-foundation/src/models/components/Baselines\")\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from torchmetrics.functional import mean_squared_error as rmse\n",
    "import lightning.pytorch as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, data, outputs, datasets, task_type, label_encoder=None):\n",
    "        self.data = data\n",
    "        self.outputs = outputs\n",
    "        self.datasets = datasets\n",
    "        self.task_type = task_type\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signals = self.data[idx]\n",
    "        output = self.outputs[idx]\n",
    "        dataset = self.datasets[idx]\n",
    "\n",
    "        if self.task_type == \"Classification\" and self.label_encoder is not None:\n",
    "            output = self.label_encoder.transform([output])[\n",
    "                0\n",
    "            ]  # Encode the output label\n",
    "            output_tensor = torch.tensor(output, dtype=torch.long)\n",
    "        else:\n",
    "            output_tensor = torch.tensor([output], dtype=torch.float32)\n",
    "\n",
    "        return {\n",
    "            \"signals\": signals,\n",
    "            \"output\": output_tensor,\n",
    "            \"dataset\": dataset,\n",
    "        }\n",
    "\n",
    "\n",
    "durs = [df.shape[1] for idx, df in train_data.items()] + [\n",
    "    df.shape[1] for idx, df in test_data.items()\n",
    "]\n",
    "n_chns = [df.shape[0] for idx, df in train_data.items()] + [\n",
    "    df.shape[0] for idx, df in test_data.items()\n",
    "]\n",
    "dur_90 = int(np.percentile(durs, 90))\n",
    "chn_90 = 128  # int(np.percentile(n_chns, 90))\n",
    "\n",
    "\n",
    "def pad_tensor(tensor, target_height, target_width):\n",
    "    current_height, current_width = tensor.shape\n",
    "\n",
    "    # Pad height if necessary\n",
    "    if current_height < target_height:\n",
    "        padding_height = target_height - current_height\n",
    "        padding = torch.zeros((padding_height, current_width), dtype=tensor.dtype)\n",
    "        tensor = torch.cat((tensor, padding), dim=0)\n",
    "    else:\n",
    "        tensor = tensor[:target_height, :]\n",
    "\n",
    "    # Pad width if necessary\n",
    "    if current_width < target_width:\n",
    "        padding_width = target_width - current_width\n",
    "        padding = torch.zeros((tensor.shape[0], padding_width), dtype=tensor.dtype)\n",
    "        tensor = torch.cat((tensor, padding), dim=1)\n",
    "    else:\n",
    "        tensor = tensor[:, :target_width]\n",
    "\n",
    "    return tensor\n",
    "\n",
    "\n",
    "train_data_pad = {\n",
    "    k: pad_tensor(signals, chn_90, dur_90) for k, signals in train_data.items()\n",
    "}\n",
    "test_data_pad = {\n",
    "    k: pad_tensor(signals, chn_90, dur_90) for k, signals in test_data.items()\n",
    "}\n",
    "\n",
    "full_train_dataset = SimpleDataset(\n",
    "    train_data_pad,\n",
    "    train_outputs,\n",
    "    train_datasets,\n",
    "    task_type=task_type,\n",
    "    label_encoder=label_encoder,\n",
    ")\n",
    "test_dataset = SimpleDataset(\n",
    "    test_data_pad,\n",
    "    test_outputs,\n",
    "    train_datasets,\n",
    "    task_type=task_type,\n",
    "    label_encoder=label_encoder,\n",
    ")\n",
    "\n",
    "# Define the split ratio\n",
    "train_ratio, val_ratio = 0.85, 0.15\n",
    "\n",
    "# Calculate lengths for train and validation sets\n",
    "total_size = len(full_train_dataset)\n",
    "train_size = int(train_ratio * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbb700f-9193-41bd-a759-ed7e8830dba0",
   "metadata": {},
   "source": [
    "## XDawn + LDA ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809166e7-bffc-42eb-bb02-618bc5568323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import torch\n",
    "\n",
    "os.makedirs(\n",
    "    f\"/itet-stor/maxihuber/net_scratch/finetune_ckpts/{task_name}\", exist_ok=True\n",
    ")\n",
    "\n",
    "\n",
    "# Function to resample signals\n",
    "def resample_signals(data, srs, target_sfreq):\n",
    "    resampled_data = {}\n",
    "    for idx, signal in tqdm(data.items(), desc=\"Resampling signals\"):\n",
    "        signal_numpy = signal.numpy().astype(np.float64)  # Convert to float64\n",
    "        signal_resampled = mne.filter.resample(signal_numpy, up=target_sfreq / srs[idx])\n",
    "        resampled_data[idx] = torch.tensor(signal_resampled, dtype=torch.float32)\n",
    "    return resampled_data\n",
    "\n",
    "\n",
    "# Function to pad or truncate signals to a common length\n",
    "def pad_or_truncate_signals(data, common_length):\n",
    "    for idx, signal in tqdm(data.items(), desc=\"Pad/Truncate signals\"):\n",
    "        signal_length = signal.shape[1]\n",
    "        if signal_length < common_length:\n",
    "            pad_width = common_length - signal_length\n",
    "            signal_padded = np.pad(signal, ((0, 0), (0, pad_width)), mode=\"constant\")\n",
    "        else:\n",
    "            signal_padded = signal[:, :common_length]\n",
    "        data[idx] = torch.tensor(signal_padded.clone().detach(), dtype=torch.float32)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Function to create MNE Epochs object from data\n",
    "def create_epochs(data, outputs, channels, sfreq=1000, is_classification=True):\n",
    "    events = []\n",
    "    event_id = {}\n",
    "    epochs_data = []\n",
    "    for idx, signal in tqdm(data.items(), desc=\"Creating epochs\"):\n",
    "        epochs_data.append(signal.numpy())\n",
    "        if is_classification:\n",
    "            if outputs[idx] not in event_id:\n",
    "                event_id[outputs[idx]] = len(event_id) + 1\n",
    "            events.append([idx, 0, event_id[outputs[idx]]])\n",
    "        else:\n",
    "            events.append([idx, 0, 1])  # Dummy event_id for regression\n",
    "    events = np.array(events, dtype=int)\n",
    "    info = mne.create_info(\n",
    "        ch_names=[f\"EEG_{i}\" for i in range(chn_90)], sfreq=sfreq, ch_types=\"eeg\"\n",
    "    )\n",
    "    epochs = mne.EpochsArray(\n",
    "        np.array(epochs_data),\n",
    "        info,\n",
    "        events=events,\n",
    "        event_id=event_id if is_classification else None,\n",
    "    )\n",
    "    return epochs\n",
    "\n",
    "\n",
    "# Determine the target sampling frequency (e.g., the highest or mean sampling rate)\n",
    "target_sfreq = int(max(train_sr.values()))  # or use statistics.mean(train_sr.values())\n",
    "\n",
    "# Resample train and test data\n",
    "# train_data_resampled = resample_signals(train_data_pad, train_sr, target_sfreq)\n",
    "# test_data_resampled = resample_signals(test_data_pad, test_sr, target_sfreq)\n",
    "train_data_resampled = train_data_pad\n",
    "test_data_resampled = test_data_pad\n",
    "\n",
    "# Determine the common length for all signals\n",
    "common_length = min(\n",
    "    min(signal.shape[1] for signal in train_data_resampled.values()),\n",
    "    min(signal.shape[1] for signal in test_data_resampled.values()),\n",
    ")\n",
    "\n",
    "# Pad or truncate train and test data to the common length\n",
    "train_data_padded = pad_or_truncate_signals(train_data_resampled, common_length)\n",
    "test_data_padded = pad_or_truncate_signals(test_data_resampled, common_length)\n",
    "\n",
    "# Convert train and test data to MNE Epochs\n",
    "is_classification = isinstance(list(train_outputs.values())[0], str)\n",
    "epochs_train = create_epochs(\n",
    "    train_data_padded,\n",
    "    train_outputs,\n",
    "    list(train_channels.values()),\n",
    "    target_sfreq,\n",
    "    is_classification,\n",
    ")\n",
    "epochs_test = create_epochs(\n",
    "    test_data_padded,\n",
    "    test_outputs,\n",
    "    list(test_channels.values()),\n",
    "    target_sfreq,\n",
    "    is_classification,\n",
    ")\n",
    "\n",
    "# Create an xDAWN instance and fit it to the training data\n",
    "xdawn = Xdawn(n_components=2, correct_overlap=False, reg=0.1)  # Adding regularization\n",
    "xdawn.fit(epochs_train)\n",
    "\n",
    "# Transform the data using xDAWN\n",
    "X_train_xdawn = xdawn.transform(epochs_train)\n",
    "X_test_xdawn = xdawn.transform(epochs_test)\n",
    "\n",
    "# Save xDAWN model parameters\n",
    "with open(\n",
    "    f\"/itet-stor/maxihuber/net_scratch/finetune_ckpts/{task_name}/xdawn_model.pkl\", \"wb\"\n",
    ") as f:\n",
    "    pickle.dump(xdawn, f)\n",
    "\n",
    "# Flatten the transformed data for LDA input\n",
    "n_epochs_train, n_components, n_times = X_train_xdawn.shape\n",
    "X_train_xdawn = X_train_xdawn.reshape(n_epochs_train, n_components * n_times)\n",
    "n_epochs_test, n_components, n_times = X_test_xdawn.shape\n",
    "X_test_xdawn = X_test_xdawn.reshape(n_epochs_test, n_components * n_times)\n",
    "\n",
    "if is_classification:\n",
    "    # Encode labels if they are strings (for classification tasks)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(list(train_outputs.values()))\n",
    "    y_test = label_encoder.transform(list(test_outputs.values()))\n",
    "\n",
    "    # Create an LDA instance and fit it to the transformed training data\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(X_train_xdawn, y_train)\n",
    "\n",
    "    # Save LDA model parameters\n",
    "    with open(\n",
    "        f\"/itet-stor/maxihuber/net_scratch/finetune_ckpts/{task_name}/lda_model.pkl\",\n",
    "        \"wb\",\n",
    "    ) as f:\n",
    "        pickle.dump(lda, f)\n",
    "\n",
    "    # Predict the labels of the test set\n",
    "    y_pred = lda.predict(X_test_xdawn)\n",
    "\n",
    "    # Calculate metrics\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    print(f\"Balanced Accuracy: {balanced_acc}\", file=sys.stderr)\n",
    "else:\n",
    "    # For regression tasks\n",
    "    y_train = np.array(list(train_outputs.values()))\n",
    "    y_test = np.array(list(test_outputs.values()))\n",
    "\n",
    "    # Create a linear regression model and fit it to the transformed training data\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_xdawn, y_train)\n",
    "\n",
    "    # Save Linear Regression model parameters\n",
    "    with open(\n",
    "        f\"/itet-stor/maxihuber/net_scratch/finetune_ckpts/{task_name}/linear_regression_model.pkl\",\n",
    "        \"wb\",\n",
    "    ) as f:\n",
    "        pickle.dump(lr, f)\n",
    "\n",
    "    # Predict the values of the test set\n",
    "    y_pred = lr.predict(X_test_xdawn)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse_value = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f\"RMSE: {rmse_value}\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6207e6f-10f8-4112-b9bd-169b0c870efd",
   "metadata": {},
   "source": [
    "## Classifiers from Sklearn  ==========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac03c514-ca57-481e-9371-ef0f1ed06c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors\n",
      "0.6111111111111112\n",
      "Linear SVM\n",
      "0.5\n",
      "RBF SVM\n",
      "0.5\n",
      "Gaussian Process\n",
      "0.5416666666666666\n",
      "Decision Tree\n",
      "0.5555555555555556\n",
      "Random Forest\n",
      "0.5416666666666666\n",
      "Neural Net\n",
      "0.5\n",
      "AdaBoost\n",
      "0.4861111111111111\n",
      "Naive Bayes\n",
      "0.5\n",
      "QDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5694444444444444\n"
     ]
    }
   ],
   "source": [
    "# Code source: GaÃ«l Varoquaux\n",
    "#              Andreas MÃ¼ller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "# https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    # \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    # \"Neural Net (MLP)\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(gamma=2, C=1, random_state=42),\n",
    "    # GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "    ),\n",
    "    # MLPClassifier(alpha=1, max_iter=100, random_state=42),\n",
    "    AdaBoostClassifier(algorithm=\"SAMME\", random_state=42),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "#Â TODO: \n",
    "\n",
    "X_train = [sample[13] for sample in train_data_pad.values()]\n",
    "y_train = [output for output in train_outputs.values()]\n",
    "\n",
    "X_test = [sample[13] for sample in test_data_pad.values()]\n",
    "y_test = [output for output in test_outputs.values()]\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(name, file=sys.stderr)\n",
    "    clf = make_pipeline(StandardScaler(), clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test, scoring=\"balanced_accuracy\")\n",
    "    print(score, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ba79b8-a869-4db1-999f-42af1fb78245",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Baseline Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29da6f7-7bce-47a8-963a-33d29acf274b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Template Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db165af-46ac-410e-b4b7-1f38794e2a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_collate_fn(batch):\n",
    "    signals = torch.stack([batch[i][\"signals\"] for i in range(len(batch))])\n",
    "    outputs = torch.stack([batch[i][\"output\"] for i in range(len(batch))])\n",
    "    #print([[dataset_dict[batch[i][\"dataset\"]]] for i in range(len(batch))])\n",
    "    datasets = torch.tensor([[dataset_dict[batch[i][\"dataset\"]]] for i in range(len(batch))])\n",
    "    #signals, output, dataset = batch[0][\"signals\"], batch[0][\"output\"], batch[0][\"dataset\"]\n",
    "    #signals = signals.unsqueeze(0)\n",
    "    #print(f\"[sample_collate_fn] signals.shape: {signals.shape}\")\n",
    "    return signals, outputs, datasets\n",
    "\n",
    "# Define the baseline model class\n",
    "class BaselineModel(L.LightningModule):\n",
    "    def __init__(self, out_dim, task_name, task_type, learning_rate, class_weights=None):\n",
    "        super(BaselineModel, self).__init__()\n",
    "\n",
    "        self.task_name = task_name\n",
    "        self.task_type = task_type\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.out_dim = out_dim\n",
    "        if task_type == \"Regression\":\n",
    "            self.criterion = nn.MSELoss()\n",
    "        else:\n",
    "            if class_weights is not None:\n",
    "                self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "            else:\n",
    "                self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.train_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, dataset = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(input=y_hat, target=y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "\n",
    "        if self.task_type == \"Classification\":\n",
    "            y_pred = torch.argmax(y_hat, dim=0)\n",
    "            #print(f\"[test_step] y_pred={y_pred}, y={y}\")\n",
    "            for i in range(len(y_pred)):\n",
    "                self.train_step_outputs.append((y[i].cpu(), y_pred[i].cpu(), dataset[i]))\n",
    "        elif self.task_type == \"Regression\":\n",
    "            for i in range(len(y_pred)):\n",
    "                self.train_step_outputs.append((y[i].cpu(), y_hat[i].cpu(), dataset[i]))\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.compute_metrics(self.train_step_outputs, 'train')\n",
    "        self.train_step_outputs.clear()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, dataset = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(input=y_hat, target=y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "        if self.task_type == \"Classification\":\n",
    "            y_pred = torch.argmax(y_hat, dim=0)\n",
    "            #print(f\"[test_step] y_pred={y_pred}, y={y}\")\n",
    "            for i in range(len(y_pred)):\n",
    "                self.validation_step_outputs.append((y[i].cpu(), y_pred[i].cpu(), dataset[i]))\n",
    "        elif self.task_type == \"Regression\":\n",
    "            for i in range(len(y_pred)):\n",
    "                self.validation_step_outputs.append((y[i].cpu(), y_hat[i].cpu(), dataset[i]))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.compute_metrics(self.validation_step_outputs, 'val')\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, dataset = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(input=y_hat, target=y)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "\n",
    "        if self.task_type == \"Classification\":\n",
    "            y_pred = torch.argmax(y_hat, dim=0)\n",
    "            #print(f\"[test_step] y_pred={y_pred}, y={y}\")\n",
    "            for i in range(len(y_pred)):\n",
    "                self.test_step_outputs.append((y[i].cpu(), y_pred[i].cpu(), dataset[i]))\n",
    "        elif self.task_type == \"Regression\":\n",
    "            for i in range(len(y_pred)):\n",
    "                self.test_step_outputs.append((y[i].cpu(), y_hat[i].cpu(), dataset[i]))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.compute_metrics(self.test_step_outputs, 'test')\n",
    "        self.test_step_outputs.clear()\n",
    "\n",
    "    def compute_metrics(self, outputs, stage):\n",
    "        y_true_all = defaultdict(list)\n",
    "        y_pred_all = defaultdict(list)\n",
    "        \n",
    "        for y_true, y_pred, dataset in outputs:\n",
    "            y_true_all[dataset].append(y_true)\n",
    "            y_pred_all[dataset].append(y_pred)\n",
    "\n",
    "        overall_y_true = []\n",
    "        overall_y_pred = []\n",
    "\n",
    "        for dataset in y_true_all.keys():\n",
    "            y_true_cat = torch.stack(y_true_all[dataset])\n",
    "            y_pred_cat = torch.stack(y_pred_all[dataset])\n",
    "\n",
    "            overall_y_true.append(y_true_cat)\n",
    "            overall_y_pred.append(y_pred_cat)\n",
    "\n",
    "            if self.task_type == \"Classification\":\n",
    "                balanced_acc = balanced_accuracy_score(y_true_cat, y_pred_cat)\n",
    "                self.log(f'{stage}_balanced_accuracy_{dataset}', balanced_acc, prog_bar=True)\n",
    "            elif self.task_type == \"Regression\":\n",
    "                rmse_value = rmse(y_true_cat, y_pred_cat)\n",
    "                self.log(f'{stage}_rmse_{dataset}', rmse_value, prog_bar=True)\n",
    "\n",
    "        # Compute overall metrics\n",
    "        overall_y_true = torch.cat(overall_y_true, dim=0)\n",
    "        overall_y_pred = torch.cat(overall_y_pred, dim=0)\n",
    "\n",
    "        if self.task_type == \"Classification\":\n",
    "            balanced_acc = balanced_accuracy_score(overall_y_true, overall_y_pred)\n",
    "            self.log(f'{stage}_balanced_accuracy', balanced_acc, prog_bar=True)\n",
    "        elif self.task_type == \"Regression\":\n",
    "            rmse_value = rmse(overall_y_true, overall_y_pred)\n",
    "            self.log(f'{stage}_rmse', rmse_value, prog_bar=True)\n",
    "            \n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f38c5-57e1-480f-8707-e04b73a619bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "62353f42-6d50-4619-b00a-de252dcf611c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "L.seed_everything(42)\n",
    "\n",
    "from src.models.components.Baselines.DL_Models.torch_models.Modules import Pad_Conv2d\n",
    "\n",
    "class EEGNetBaselineModel(BaselineModel):\n",
    "    def __init__(self, out_dim, task_name, task_type, learning_rate, class_weights):\n",
    "        super(EEGNetBaselineModel, self).__init__(out_dim, task_name, task_type, learning_rate, class_weights)\n",
    "        \n",
    "        self.T = dur_90\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, chn_90), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "        \n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints. \n",
    "        self.fc1 = nn.Linear(4*2*(dur_90//16), out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.permute(0,2,1)\n",
    "        x.unsqueeze_(0)\n",
    "\n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "        \n",
    "        # FC Layer\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(-1, 4*2*(dur_90//16))\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57c992-ae5f-4c72-8c72-7ce0353c479d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4a8138e8-339a-47ce-9c8f-93ab2bf7410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "L.seed_everything(42)\n",
    "\n",
    "import math\n",
    "from src.models.components.Baselines.DL_Models.torch_models.UNet.UNet import Block, Encoder, Decoder\n",
    "\n",
    "class UNetBaselineModel(BaselineModel):\n",
    "    def __init__(self, out_dim, task_name, task_type, learning_rate, class_weights):\n",
    "        super(UNetBaselineModel, self).__init__(out_dim, task_name, task_type, learning_rate, class_weights)\n",
    "        \n",
    "        self.output_channel = 128  # Assuming the last decoder channel is 128\n",
    "        self.nb_outlayer_channels = 1\n",
    "        self.timesamples = dur_90\n",
    "        self.input_channels = chn_90\n",
    "        self.encChannels = (self.input_channels,) + (128, 256, 512)\n",
    "        self.decChannels = (1024,) + (512, 256, 128)\n",
    "        self.pools = (10, 5, 5)\n",
    "        self.encoder = Encoder(filters=self.encChannels, output_size=1024, pools=self.pools)\n",
    "        self.decoder = Decoder(filters=self.decChannels, pools=self.pools[::-1])\n",
    "        \n",
    "        self.output_layer = nn.Conv1d(\n",
    "            in_channels=self.get_nb_channels_output_layer(),\n",
    "            out_channels=1,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "        )\n",
    "        self.out_linear = nn.Linear(self.timesamples, self.out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.permute(0, 2, 1)\n",
    "        batchsize, channels, seq_length = x.size()\n",
    "        encFeatures = self.encoder(x)\n",
    "        decFeatures = self.decoder(encFeatures[::-1][0], encFeatures[::-1][1:])\n",
    "        _, _, segment_length = decFeatures.size()\n",
    "        top = math.floor((seq_length - segment_length) / 2)\n",
    "        bottom = math.ceil((seq_length - segment_length) / 2)\n",
    "        output = nn.ZeroPad2d(padding=(bottom, top, 0, 0))(decFeatures)\n",
    "        output = self.output_layer(output)\n",
    "        output = self.out_linear(output)\n",
    "        #print(output.shape)\n",
    "        output.squeeze_(0).squeeze_(0)\n",
    "        #output = output.permute(0, 2, 1)\n",
    "        return output\n",
    "\n",
    "    def get_nb_channels_output_layer(self):\n",
    "        return self.output_channel\n",
    "\n",
    "    def get_nb_features_output_layer(self):\n",
    "        return self.output_channel * self.timesamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e90663-0ef2-4e02-958d-011157b124dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1232fa74-7adf-44a7-add2-111c3cf353ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "L.seed_everything(42)\n",
    "\n",
    "sys.path.append(\"/home/maxihuber/eeg-foundation/src/models/components/Baselines\")\n",
    "from src.models.components.Baselines.DL_Models.torch_models.CNN.CNN import CNN\n",
    "\n",
    "from src.models.components.Baselines.DL_Models.torch_models.Modules import Pad_Conv, Pad_Pool\n",
    "from lightning.pytorch import LightningModule\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "class CNNBaselineModel(BaselineModel):\n",
    "    def __init__(self, out_dim, task_name, task_type, learning_rate, class_weights):\n",
    "        super(CNNBaselineModel, self).__init__(out_dim, task_name, task_type, learning_rate, None)\n",
    "        \n",
    "        self.nb_features = 128  # For CNN simply the number of filters / channels\n",
    "        self.nb_outlayer_channels = 1\n",
    "        self.use_residual = True\n",
    "        self.depth = 12\n",
    "        self.kernel_size = 128\n",
    "        self.nb_channels = 1\n",
    "        \n",
    "        self.conv_blocks = nn.ModuleList([self._module(d) for d in range(self.depth)])\n",
    "        if self.use_residual:\n",
    "            self.shortcuts = nn.ModuleList(\n",
    "                [self._shortcut(d) for d in range(int(self.depth / 3))]\n",
    "            )\n",
    "        self.gap_layer = nn.AvgPool1d(kernel_size=2, stride=1)\n",
    "        self.gap_layer_pad = Pad_Pool(left=0, right=1, value=0)\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=self.get_nb_channels_output_layer(),\n",
    "                out_channels=min(self.get_nb_features_output_layer(), self.nb_outlayer_channels),\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "            ),\n",
    "            nn.BatchNorm1d(num_features=self.nb_outlayer_channels),\n",
    "            nn.ReLU(),\n",
    "            Pad_Pool(left=0, right=1, value=0),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=1),\n",
    "        )\n",
    "        self.out_linear = nn.Sequential(\n",
    "            nn.Linear(dur_90, 32),\n",
    "        )\n",
    "        self.final_layer = nn.Linear(32, self.out_dim)\n",
    "    \n",
    "    def _module(self, depth):\n",
    "        \"\"\"\n",
    "        The module of CNN is made of a simple convolution with batch normalization and ReLu\n",
    "        activation. Finally, MaxPooling is used. We use two custom padding modules such that\n",
    "        keras-like padding='same' is achieved, i.e. tensor shape stays constant when passed through\n",
    "        the module.\n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            Pad_Conv(kernel_size=self.kernel_size, value=0),\n",
    "            nn.Conv1d(\n",
    "                in_channels=self.nb_channels if depth == 0 else self.nb_features,\n",
    "                out_channels=self.nb_features,\n",
    "                kernel_size=self.kernel_size,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm1d(num_features=self.nb_features),\n",
    "            nn.ReLU(),\n",
    "            Pad_Pool(left=0, right=1, value=0),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=1),\n",
    "        )\n",
    "\n",
    "    def _shortcut(self, depth):\n",
    "        \"\"\"\n",
    "        Implements a shortcut with a convolution and batch norm\n",
    "        This is the same for all models implementing ConvNet, therefore defined here\n",
    "        Padding before convolution for constant tensor shape, similar to tensorflow.keras padding=same\n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            Pad_Conv(kernel_size=self.kernel_size, value=0),\n",
    "            nn.Conv1d(\n",
    "                in_channels=self.nb_channels if depth == 0 else self.nb_features,\n",
    "                out_channels=self.nb_features,\n",
    "                kernel_size=self.kernel_size,\n",
    "            ),\n",
    "            nn.BatchNorm1d(num_features=self.nb_features),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Implements the forward pass of the network\n",
    "        Modules defined in a class implementing ConvNet are stacked and shortcut connections are\n",
    "        used if specified.\n",
    "        \"\"\"\n",
    "        B, C, T = x.shape\n",
    "        x = x.reshape(B * C, 1, T)\n",
    "        #print(f\"Input shape: {x.shape}\")\n",
    "        input_res = x  # set for the residual shortcut connection\n",
    "        shortcut_cnt = 0\n",
    "        for d in range(self.depth):\n",
    "            x = self.conv_blocks[d](x)\n",
    "            if self.use_residual and d % 3 == 2:\n",
    "                res = self.shortcuts[shortcut_cnt](input_res)\n",
    "                shortcut_cnt += 1\n",
    "                x = torch.add(x, res)\n",
    "                x = nn.functional.relu(x)\n",
    "                input_res = x\n",
    "        x = self.gap_layer_pad(x)\n",
    "        x = self.gap_layer(x)\n",
    "        output = self.output_layer(x)\n",
    "        output = self.out_linear(output)\n",
    "        output = output.reshape(B, C, 32)\n",
    "        output = torch.mean(output, dim=1)\n",
    "        output = self.final_layer(output)\n",
    "        output.squeeze_(0).squeeze_(0)\n",
    "        return output\n",
    "\n",
    "    def get_nb_features_output_layer(self):\n",
    "        return self.nb_features\n",
    "    \n",
    "    def get_nb_channels_output_layer(self):\n",
    "        return self.nb_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e4663a-3f56-46fa-b037-707a022d9805",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Training Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "280f25bd-e585-4468-b860-ab5a3ddd9585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors\n",
      "0.59\n",
      "Linear SVM\n",
      "0.69\n",
      "RBF SVM\n",
      "0.495\n",
      "Gaussian Process\n",
      "0.56\n",
      "Decision Tree\n",
      "0.56\n",
      "Random Forest\n",
      "0.515\n",
      "Neural Net\n",
      "0.55\n",
      "AdaBoost\n",
      "0.52\n",
      "Naive Bayes\n",
      "0.535\n",
      "QDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/itet-stor/maxihuber/net_scratch/conda_envs/fastenv/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa41d18-c3c4-45c1-a392-cc026c818004",
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(42)\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, collate_fn=sample_collate_fn, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, collate_fn=sample_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, collate_fn=sample_collate_fn)\n",
    "\n",
    "baseline = \"CNN\"\n",
    "\n",
    "if baseline == \"CNN\":\n",
    "    baseline_model = CNNBaselineModel(out_dim=out_dim, task_name=task_name, task_type=task_type, learning_rate=0.0002, class_weights=weight_tensor)\n",
    "elif baseline == \"EEG1Net\":\n",
    "    baseline_model = EEG1NetBaselineModel(out_dim=out_dim, task_name=task_name, task_type=task_type, learning_rate=5e-5, class_weights=weight_tensor)\n",
    "elif baseline == \"EEG2Net\":\n",
    "    baseline_model = EEG1NetBaselineModel(out_dim=out_dim, task_name=task_name, task_type=task_type, learning_rate=5e-5, class_weights=weight_tensor)\n",
    "elif baseline == \"UNet\":\n",
    "    baseline_model = UNetBaselineModel(out_dim=out_dim, task_name=task_name, task_type=task_type, learning_rate=5e-5, class_weights=weight_tensor)\n",
    "else:\n",
    "    assert False, \"no valid baseline model specified\"\n",
    "\n",
    "# Define the checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"/itet-stor/maxihuber/net_scratch/finetune_ckpts/{task_name}_{baseline}\",\n",
    "    filename=\"{epoch:02d}-{val_loss:.2f}\",\n",
    "    save_top_k=3,\n",
    "    monitor=\"val_balanced_accuracy\" if task_type == \"Classification\" else \"val_rmse\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=30,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    log_every_n_steps=1,\n",
    ")\n",
    "print(f\"Baseline Model: {baseline}\")\n",
    "print(f\"Class: {class_name}\")\n",
    "print(f\"Task: {task_name} ({task_type})\")\n",
    "trainer.fit(baseline_model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "trainer.test(model=baseline_model, dataloaders=test_loader)\n",
    "final_checkpoint_path = f\"/itet-stor/maxihuber/net_scratch/finetune_ckpts/{task_name}_{baseline}/final_model.ckpt\"\n",
    "trainer.save_checkpoint(final_checkpoint_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
